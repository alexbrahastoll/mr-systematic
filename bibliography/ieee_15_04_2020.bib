@INPROCEEDINGS{8068545,
author={L. E. {Nugroho} and A. {Azis} and I. W. {Mustika} and {Selo}},
booktitle={2017 7th International Annual Engineering Seminar (InAES)},
title={Development of RESTful API to support the oil palm plantation monitoring system},
year={2017},
volume={},
number={},
pages={1-5},
abstract={In this research, RESTful API as a service provider of data resource of oil palm plantation from the database using Resource-Oriented Architecture (ROA)-Slim Framework is developed. This development is able to result in a series of URI to access the data resources of the condition of the plantation environment as the support of monitoring system in oil palm plantation. Based upon the result of the test on functionality, it has been found that API as the support of the monitoring system of oil palm plantation has fulfilled the basic needs of the process of monitoring the condition of oil palm environment in accordance with the design specification referred to the needs identification.},
keywords={application program interfaces;computerised monitoring;condition monitoring;environmental factors;industrial plants;petroleum industry;production engineering computing;software architecture;Resource-Oriented Architecture-Slim Framework;data resource;ROA-Slim Framework;oil palm plantation monitoring system;RESTful API;oil palm environment;plantation environment;Oils;Monitoring;Information systems;Databases;Logic gates;Seminars;Computer architecture;RESTful API;Slim framework;Oil palm plantation monitoring system},
doi={10.1109/INAES.2017.8068545},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8421389,
author={B. {Di Martino} and A. {Posillipo} and S. {Nacchia} and S. A. {Maisto}},
booktitle={2018 IEEE International Conference on Smart Computing (SMARTCOMP)},
title={A Q A Tool to Produce an Ad-Hoc OpenAPI Specification to Identify Equivalent REST Api Services},
year={2018},
volume={},
number={},
pages={375-380},
abstract={The highly heterogeneous environment of IoT (Internet of Things) and Smart cities guarantees that every stakeholder's requirements can be achieved and implemented. However deciding which is the most appropriate sensor to adopt among various similar ones and, even most important, how to use it is not an easy task; a task that, as of today, cannot be done without access to source code or documentation. Moreover heterogeneity in descriptions and definitions complicate sensor interfaces comparison and selection, and may create interoperability and portability problems among multiple providers. In this work we aim at providing a Q&A tool that guides the user in the production of a RESTApi sensor's interfaces according to the OpenAPI specification. The automatically produced ad-hoc specification is used as a base for defining sensors' interfaces equivalence and similarity using natural language processing techniques.},
keywords={ad hoc networks;application program interfaces;Internet of Things;natural language processing;open systems;question answering (information retrieval);sensors;smart cities;interoperability;portability problems;Q&A tool;IoT;Internet of things;smart cities;stakeholders requirement;natural language processing techniques;RESTApi sensor interface;application program interface;equivalent REST Api services identification;ad-hoc OpenAPI specification;Tools;Documentation;Standards;Electronic mail;Task analysis;Natural language processing;Servers;IoT;Rest API;OpenAPI Specification;Q&A Tool;NLP;Text similarity;Natural Language Processing},
doi={10.1109/SMARTCOMP.2018.00032},
ISSN={},
month={June},}
@INPROCEEDINGS{6498563,
author={D. {Liu} and H. {Zhu} and I. {Bayley}},
booktitle={2013 21st Euromicro International Conference on Parallel, Distributed, and Network-Based Processing},
title={A Case Study on Algebraic Specification of Cloud Computing},
year={2013},
volume={},
number={},
pages={269-273},
abstract={A cloud often provides a RESTful interface with which to access its services. These are usually specified through an open but informal document in the IT industry. There is no agreed standard for the specification of RESTful web services. In this paper, we propose the application of an algebraic method to the formal specification of such services and report a case study with the GoGrid's RESTful API, an industrial real system that provides Infrastructure-as-a-Service. The case study demonstrates that the algebraic approach can provide formal unambiguous specifications that are easy to read and write. It also demonstrates that formalisation can identify and eliminate ambiguity and inconsistency in informal documents.},
keywords={algebra;application program interfaces;cloud computing;formal specification;Web services;algebraic specification;cloud computing;RESTful interface;IT industry;RESTful Web services;infrastructure-as-a-service;formal unambiguous specifications;informal documents;RESTful API;Semantics;Observers;Servers;Authentication;Cloud computing;Search problems;Cloud computing;RESTful Web Services;Formal specification;Algebraic specification},
doi={10.1109/PDP.2013.46},
ISSN={2377-5750},
month={Feb},}
@INPROCEEDINGS{8811961,
author={V. {Atlidakis} and P. {Godefroid} and M. {Polishchuk}},
booktitle={2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)},
title={RESTler: Stateful REST API Fuzzing},
year={2019},
volume={},
number={},
pages={748-758},
abstract={This paper introduces RESTler, the first stateful REST API fuzzer. RESTler analyzes the API specification of a cloud service and generates sequences of requests that automatically test the service through its API. RESTler generates test sequences by (1) inferring producer-consumer dependencies among request types declared in the specification (e.g., inferring that "a request B should be executed after request A" because B takes as an input a resource-id x produced by A) and by (2) analyzing dynamic feedback from responses observed during prior test executions in order to generate new tests (e.g., learning that "a request C after a request sequence A;B is refused by the service" and therefore avoiding this combination in the future). We present experimental results showing that these two techniques are necessary to thoroughly exercise a service under test while pruning the large search space of possible request sequences. We used RESTler to test GitLab, an open-source Git service, as well as several Microsoft Azure and Office365 cloud services. RESTler found 28 bugs in GitLab and several bugs in each of the Azure and Office365 cloud services tested so far. These bugs have been confirmed and fixed by the service owners.},
keywords={application program interfaces;cloud computing;fuzzy set theory;program debugging;program testing;prior test executions;request C;test GitLab;open-source Git service;Office365 cloud services;service owners;stateful REST API fuzzing;stateful REST API fuzzer;RESTler analyzes;API specification;cloud service;test sequences;request types;request B;request sequences;Microsoft Azure cloud services;bugs;Computer bugs;Tools;Fuzzing;Dictionaries;Open source software;Test pattern generators;REST API;Fuzzing;cloud services;fuzzer;testing;bug finding},
doi={10.1109/ICSE.2019.00083},
ISSN={1558-1225},
month={May},}
@INPROCEEDINGS{7195555,
author={M. {Fokaefs} and E. {Stroulia}},
booktitle={2015 IEEE International Conference on Web Services},
title={Using WADL Specifications to Develop and Maintain REST Client Applications},
year={2015},
volume={},
number={},
pages={81-88},
abstract={Service orientation is one of the most popular paradigms for developing modular distributed software systems. In spite of the substantial research effort dedicated to the development of methods and tools to support SOAP-based service-oriented application development, in practice, RESTful services have surpassed SOAP-based services in popularity and adoption, primarily due to the simplicity of their invocation. However, poor adoption of REST specification standards and lack of systematic development tools have given rise to many, more or less compliant, variants of the Restful style constraints, which undermine the evolvability and interoperability of these systems. In this paper, we describe a tool that supports the systematization of RESTful application development, through the use of semi-automatically constructed WADL interface specifications, without compromising the ease of the overall practice. We illustrate the use and advantages of our tool on real-world REST APIs. Additionally, we comment on how REST APIs are documented, especially in comparison to the auto-generated WADLs.},
keywords={application program interfaces;formal specification;Internet;service-oriented architecture;software maintenance;specification languages;REST client application maintenance;modular distributed software system development;SOAP-based service-oriented application development;RESTful service;invocation;REST specification standard;system evolvability;system interoperability;RESTful application development;WADL interface specification;REST API;autogenerated WADL;Generators;Uniform resource locators;Documentation;Google;Software;XML;Blogs},
doi={10.1109/ICWS.2015.21},
ISSN={},
month={June},}
@INPROCEEDINGS{8536162,
author={H. {Ed-douibi} and J. L. {CÃ¡novas Izquierdo} and J. {Cabot}},
booktitle={2018 IEEE 22nd International Enterprise Distributed Object Computing Conference (EDOC)},
title={Automatic Generation of Test Cases for REST APIs: A Specification-Based Approach},
year={2018},
volume={},
number={},
pages={181-190},
abstract={The REpresentation State Transfer (REST) has gained momentum as the preferred technique to design Web APIs. REST allows building loosely coupled systems by relying on HTTP and the Web-friendly format JSON. However, REST is not backed by any standard or specification to describe how to create/consume REST APIs, thus creating new challenges for their integration, testing and verification. To face this situation, several specification formats have been proposed (e.g., OpenAPI, RAML, and API Blueprint), which can help automate tasks in REST API development (e.g., testing) and consumption (e.g., SDKs generation). In this paper we focus on automated REST API testing relying on API specifications, and particularly the OpenAPI one. We propose an approach to generate specification-based test cases for REST APIs to make sure that such APIs meet the requirements defined in their specifications. We provide a proof-of-concept tool implementing our approach, which we have validated with 91 OpenAPI definitions. Our experiments show that the generated test cases cover on average 76.5% of the elements included in the OpenAPI definitions. Furthermore, our experiments also reveal that 40% of the tested APIs fail.},
keywords={application program interfaces;formal specification;formal verification;Internet;program testing;Web-friendly format JSON;REST API development;specification-based test cases;loosely coupled systems;HTTP;proof-of-concept;openAPI definitions;representation state transfer;Testing;Tools;Task analysis;Reliability;Internet;Standards;Face;API testing;REST APIs;OpenAPI},
doi={10.1109/EDOC.2018.00031},
ISSN={2325-6362},
month={Oct},}
@ARTICLE{8325321,
author={F. {Palma} and N. {Moha} and Y. {GuÃ©hÃ©neuc}},
journal={IEEE Transactions on Software Engineering},
title={UniDoSA: The Unified Specification and Detection of Service Antipatterns},
year={2019},
volume={45},
number={10},
pages={1024-1053},
abstract={Service-based Systems (SBSs) are developed on top of diverse Service-Oriented Architecture (SOA) technologies or architectural styles. Like any other complex systems, SBSs face both functional and non-functional changes at the design or implementation-level. Such changes may degrade the design quality and quality of service (QoS) of the services in SBSs by introducing poor solutions-service antipatterns. The presence of service antipatterns in SBSs may hinder the future maintenance and evolution of SBSs. Assessing the quality of design and QoS of SBSs through the detection of service antipatterns may ease their maintenance and evolution. However, the current literature lacks a unified approach for modelling and evaluating the design of SBSs in term of design quality and QoS. To address this lack, this paper presents a meta-model unifying the three main service technologies: REST, SCA, and SOAP. Using the meta-model, it describes a unified approach, UniDoSA (Unified Specification and Detection of Service Antipatterns), supported by a framework, SOFA (Service Oriented Framework for Antipatterns), for modelling and evaluating the design quality and QoS of SBSs. We apply and validate UniDoSA on: (1) 18 RESTful APIs, (2) two SCA systems with more than 150 services, and (3) more than 120 SOAP Web services. With a high precision and recall, the detection results provide evidence of the presence of service antipatterns in SBSs, which calls for future studies of their impact on QoS.},
keywords={application program interfaces;formal specification;quality of service;service-oriented architecture;software maintenance;software quality;Web services;Unified Specification;SOAP Web services;Service-based Systems;service-oriented architecture;SBS;UniDoSA;service antipattern detection;service oriented framework for antipatterns;SOFA;SCA;quality of service;QoS;RESTful API;Simple object access protocol;Quality of service;Service-oriented architecture;Maintenance engineering;DSL;Antipatterns;service-based systems;REST;SCA;SOAP;web services;specification;detection;quality of service;design;software maintenance and evolution},
doi={10.1109/TSE.2018.2819180},
ISSN={1939-3520},
month={Oct},}
@ARTICLE{6712032,
author={},
journal={IEEE Std 1874-2013},
title={IEEE Standard for Documentation Schema for Repair and Assembly of Electronic Devices},
year={2014},
volume={},
number={},
pages={1-42},
abstract={oManual is a standard for storing and transmitting procedural manuals. oManuals common data format can be used as an offline file package or via online RESTful API endpoints, using XML or JSON. This format is useful for documenting and describing repairs, how-to, workinstructions, or any other step-by-step guides. oManual makes it easy to exchange procedural information between services while maintaining usability on mobile devices.This specification describes the oManual data model, web services API, and bundle file format (a collection of structured files containing a category XML format, a guide XML format and related multimedia). The specification may be expanded in the future to enable additional types of documents.},
keywords={application program interfaces;assembling;electronic data interchange;electronic engineering computing;file organisation;IEEE standards;Java;maintenance engineering;software packages;user manuals;Web services;XML;bundle file format;Web services;oManual data model;mobile devices;procedural information exchange;JSON;XML;online RESTful API endpoints;offline file package;data format;procedural manuals;documentation schema;electronic device repair;electronic device assembly;IEEE Std 1874-2013;IEEE standards;Maintenance engineering;Equipment maintenance;IEEE 1874(TM);JSON;manual;oEmbed;oManual;RESTful API;XML;ZIP},
doi={10.1109/IEEESTD.2014.6712032},
ISSN={},
month={Jan},}
@INPROCEEDINGS{8029826,
author={S. {Liu} and Y. {Li} and G. {Sun} and B. {Fan} and S. {Deng}},
booktitle={2017 IEEE International Conference on Web Services (ICWS)},
title={Hierarchical RNN Networks for Structured Semantic Web API Model Learning and Extraction},
year={2017},
volume={},
number={},
pages={708-713},
abstract={RESTful Web APIs have no description files like WSDL in traditional Web service. Although some REST API definition models have been arising recently, there is still lacking in structured description format for existing large mounts of Web APIs. Almost all Web APIs are documented in semi-structured web pages, and these documentation formats are various for different sites. It's hard for machine to read the semantics of Web APIs. In this paper, we have proposed a novel hierarchical recurrent neural network to convert REST API documentation to structured machine-readable description format -- the Swagger REST API specification. The network extracts the Swagger defined attributes of a REST API from HTML web pages without any feature engineering. With the extracted API specifications, we built an API repository to index, search and compose Web APIs. Experiment showed that the hierarchical RNN model performed well even with only a few training samples.},
keywords={application program interfaces;learning (artificial intelligence);recurrent neural nets;semantic Web;Web services;hierarchical RNN networks;structured semantic Web API model learning;RESTful Web APIs;traditional Web service;REST API definition models;structured description format;semistructured web pages;REST API documentation;structured machine-readable description;Swagger REST API specification;HTML web pages;extracted API specifications;API repository;hierarchical RNN model;recurrent neural network;Swagger;Web pages;Logic gates;Recurrent neural networks;HTML;Documentation;Semantics;Data mining;Web API Extraction;Swagger;RNN},
doi={10.1109/ICWS.2017.85},
ISSN={},
month={June},}
@INPROCEEDINGS{7816483,
author={R. {Pandita} and K. {Taneja} and L. {Williams} and T. {Tung}},
booktitle={2016 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
title={ICON: Inferring Temporal Constraints from Natural Language API Descriptions},
year={2016},
volume={},
number={},
pages={378-388},
abstract={Temporal constraints of an Application Programming Interface (API) are the allowed sequences of method invocations in the API governing the secure and robust operation of client software using the API. These constraints are typically described informally in natural language API documents, and therefore are not amenable to existing constraint-checking tools. Manually identifying and writing formal temporal constraints from API documents can be prohibitively time-consuming and error-prone. To address this issue, we propose ICON: an approach based on Machine Learning (ML) and Natural Language Processing (NLP) for identifying and inferring formal temporal constraints. To evaluate our approach, we use ICON to infer and formalize temporal constraints from the Amazon S3 REST API, the PayPal Payment REST API, and the java.io package in the JDK API. Our results indicate that ICON can effectively identify temporal constraint sentences (from over 4000 human annotated API sentences) with the average 79.0% precision and 60.0% recall. Furthermore, our evaluation demonstrates that ICON achieves an accuracy of 70% in inferring 77 formal temporal constraints from these APIs.},
keywords={application program interfaces;learning (artificial intelligence);natural language processing;ICON;natural language API description;application program interfaces;temporal constraints;client software;constraint-checking tools;machine learning;ML;natural language processing;NLP;Amazon S3 REST API;PayPal Payment REST API;JDK API;Natural languages;Contracts;Tagging;Documentation;Semantics;Dictionaries;Syntactics;NLP;Temporal Specifications;API},
doi={10.1109/ICSME.2016.59},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8719480,
author={M. {Hosono} and H. {Washizaki} and Y. {Fukazawa} and K. {Honda}},
booktitle={2018 25th Asia-Pacific Software Engineering Conference (APSEC)},
title={An Empirical Study on the Reliability of the Web API Document},
year={2018},
volume={},
number={},
pages={715-716},
abstract={The importance of APIs in software development, especially web APIs, has increased Developers read documentation, which is available on the internet, and use the corresponding APIs in their products. However, documentation occasionally contains mistakes. Such mistakes can confuse developers or lead to defects that lower the quality of the product. In this paper, we investigate the reliability of web APIs by extracting and comparing OpenAPI specifications from both the documentations and the results of the API calls. Almost half of the documentations are somehow unreliable. Mismatches between documentation and the response can be categorized into four types: 1) Undocumented Keys, 2) Dynamic Keys, 3) Unreturned Keys, and 4) Type Mismatched. This study will help developers design more reliable products.},
keywords={application program interfaces;document handling;Internet;software engineering;API calls;software development;Web API document;Developers read documentation;Internet;product quality;OpenAPI specifications;undocumented keys;dynamic keys;unreturned keys;type mismatched;Documentation;Indexes;Reliability engineering;Software reliability;Dictionaries;Histograms;Web API, REST API, microservices, API documentation, documentation evolution},
doi={10.1109/APSEC.2018.00103},
ISSN={2640-0715},
month={Dec},}
@INPROCEEDINGS{7839809,
author={M. {Mazumder} and T. {Braje}},
booktitle={2016 IEEE Cybersecurity Development (SecDev)},
title={Safe Client/Server Web Development with Haskell},
year={2016},
volume={},
number={},
pages={150-150},
abstract={We demonstrate how two Haskell libraries - Reflex-Dom and Servant - provide a powerful and complete web development framework which uses typechecking to guarantee many security and correctness properties on both the client and the server. With types as our guide, we can ensure that the data passed to our API is of the right shape, that we are forced to sanitize user input (eliminating most of the possibilities for SQL injection or XSS attacks), and that user input errors are guaranteed to be handled. We use Reflex, a Functional Reactive Programming engine, compiled with GHCJS (the Haskell-to-JavaScript transpiler) to lift user input into a safe representation. Types are used to enforce that all required data is requested from a user before the user can proceed to the next action in a workflow. Malformed user input is also cleanly separated at the type level for automatic reporting and recovery. Tutorial exercises will highlight Servant's guarantees that a REST API is fully specified for all possible user inputs and return conditions. Tutorial attendees will gain an appreciation of how much work this up-front specification can save in development time. For example, Servant knows what all of your endpoints are, and serves error pages for everything else. Servant can also safely handle data conversions from the world of untyped Strings into the typesafe world of your API.},
keywords={application program interfaces;client-server systems;data handling;formal specification;functional languages;Internet;program compilers;security of data;SQL;data conversion handling;up-front specification;Haskell-to-JavaScript transpiler;functional reactive programming engine;Reflex;XSS attacks;SQL injection;API;correctness properties;security properties;typechecking;Haskell libraries;safe client-server Web development;Tutorials;Servers;Syntactics;Programming;Computer security;Libraries},
doi={10.1109/SecDev.2016.040},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8595237,
author={B. A. {Sanchez} and K. {Barmpis} and P. {Neubauer} and R. F. {Paige} and D. S. {Kolovos}},
booktitle={2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)},
title={RestMule: Enabling Resilient Clients for Remote APIs},
year={2018},
volume={},
number={},
pages={537-541},
abstract={Mining data from remote repositories, such as GitHub and StackExchange, involves the execution of requests that can easily reach the limitations imposed by the respective APIs to shield their services from overload and abuse. Therefore, data mining clients are left alone to deal with such protective service policies which usually involves an extensive amount of manual implementation effort. In this work we present RestMule, a framework for handling various service policies, such as limited number of requests within a period of time and multi-page responses, by generating resilient clients that are able to handle request rate limits, network failures, response caching, and paging in a graceful and transparent manner. As a result, RestMule clients generated from OpenAPI specifications (i.e. standardized REST API descriptors), are suitable for intensive data-fetching scenarios. We evaluate our framework by reproducing an existing repository mining use case and comparing the results produced by employing a popular hand-written client and a RestMule client.},
keywords={application program interfaces;client-server systems;data mining;Internet;remote repositories;data mining clients;protective service policies;manual implementation effort;multipage responses;request rate limits;response caching;RestMule client;standardized REST API descriptors;intensive data-fetching scenarios;resilient clients;remote APIs;GitHub;StackExchange;hand-written client;network failures;OpenAPI specifications;repository mining use case;Data mining;Software;Libraries;Computer architecture;Java;Resilience;Resilience;OpenAPI Specification;HTTP API Clients},
doi={},
ISSN={2574-3864},
month={May},}
@INPROCEEDINGS{7092950,
author={A. {Slominski} and V. {Muthusamy} and R. {Khalaf}},
booktitle={2015 IEEE International Conference on Cloud Engineering},
title={Building a Multi-tenant Cloud Service from Legacy Code with Docker Containers},
year={2015},
volume={},
number={},
pages={394-396},
abstract={In this paper we address the problem of migrating a legacy Web application to a cloud service. We develop a reusable architectural pattern to do so and validate it with a case study of the Beta release of the IBM Bluemix Workflow Service [1] (herein referred to as the Beta Workflow service). It uses Docker [2] containers and a Cloudant [3] persistence layer to deliver a multi-tenant cloud service by re-using a legacy codebase. We are not aware of any literature that addresses this problem by using containers.The Beta Workflow service provides a scalable, stateful, highly available engine to compose services with REST APIs. The composition is modeled as a graph but authored in a Javascript-based domain specific language that specifies a set of activities and control flow links among these activities. The primitive activities in the language can be used to respond to HTTP REST requests, invoke services with REST APIs, and execute Javascript code to, among other uses, extract and construct the data inputs and outputs to external services, and make calls to these services.Examples of workflows that have been built using the service include distributing surveys and coupons to customers of a retail store [1], the management of sales requests between a salesperson and their regional managers, managing the staged deployment of different versions of an application, and the coordinated transfer of jobs among case workers.},
keywords={application program interfaces;cloud computing;Java;specification languages;Javascript code;HTTP REST requests;Javascript-based domain specific language;REST API;Cloudant persistence layer;Beta Workflow service;IBM Bluemix Workflow Service;reusable architectural pattern;legacy Web application;docker containers;legacy codebase;multitenant cloud service;Containers;Engines;Security;Cloud computing;Organizations;Browsers;Memory management},
doi={10.1109/IC2E.2015.66},
ISSN={},
month={March},}
@INPROCEEDINGS{7194337,
author={A. d. {Benedictis} and M. {Rak} and M. {Turtur} and U. {Villano}},
booktitle={2015 IEEE 24th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises},
title={REST-Based SLA Management for Cloud Applications},
year={2015},
volume={},
number={},
pages={93-98},
abstract={In cloud computing, possible risks linked to availability, performance and security can be mitigated by the adoption of Service Level Agreements (SLAs) formally agreed upon by cloud service providers and their users. This paper presents the design of services for the management of cloud-oriented SLAs that hinge on the use of a REST-based API. Such services can be easily integrated into existing cloud applications, platforms and infrastructures, in order to support SLA-based cloud services delivery. After a discussion on the SLA life-cycle, an agreement protocol state diagram is introduced. It takes explicitly into account negotiation, remediation and renegotiation issues, is compliant with all the active standards, and is compatible with the WS-Agreement standard. The requirement analysis and the design of a solution able to support the proposed SLA protocol is presented, introducing the REST API used. This API aims at being the basis for a framework to build SLA-based applications.},
keywords={application program interfaces;cloud computing;contracts;diagrams;formal specification;formal verification;protocols;systems analysis;REST-based SLA management;REST-based API;service level agreement;cloud computing;cloud service provider;CSP;SLA-based cloud services delivery;agreement protocol state diagram;requirement analysis;Standards;Monitoring;XML;Cloud computing;Uniform resource locators;Security;Protocols;Cloud;SLA;WS-Agreement;REST;API},
doi={10.1109/WETICE.2015.36},
ISSN={1524-4547},
month={June},}
@INPROCEEDINGS{8904508,
author={H. {Ed-douibi} and J. L. {CÃ¡novas Izquierdo} and F. {Bordeleau} and J. {Cabot}},
booktitle={2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)},
title={WAPIml: Towards a Modeling Infrastructure for Web APIs},
year={2019},
volume={},
number={},
pages={748-752},
abstract={Web APIs are becoming key assets for any business. Most of these Web APIs are "REST-like", meaning that they adhere partially to the Representational State Transfer (REST) architectural style. The OpenAPI Initiative (OAI) was launched with the objective of creating a vendor neutral, portable, and open specification for describing REST APIs. The initiative has succeeded in attracting major companies and the OpenAPI specification has become de facto format for describing REST APIs. However, there is currently a lack of tools to provide modeling facilities for developers who want to manage and visualize their OpenAPI definitions as models and integrate them into model-based processes. In this paper, we propose WAPIml an OpenAPI round-trip tool that leverages model-driven techniques to create, visualize, manage, and generate OpenAPI definitions. WAPIml embeds an OpenAPI metamodel but also an OpenAPI UML profile to enable working with Web APIs in any UML-compatible modeling tool.},
keywords={application program interfaces;software architecture;Unified Modeling Language;Web services;WAPIml;modeling infrastructure;Web API;Representational State Transfer architectural style;open specification;OpenAPI specification;modeling facilities;OpenAPI definitions;model-based processes;OpenAPI round-trip tool;leverages model-driven techniques;UML-compatible modeling tool;REST API;REST APIs;OpenAPI;UML;UML profile},
doi={10.1109/MODELS-C.2019.00116},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{7787064,
author={A. {Ruokonen} and Z. {Wu} and R. {Lu}},
booktitle={2016 IEEE International Conference on Mobile Services (MS)},
title={Describing Mobile Devices as RESTful Services for the End-Users},
year={2016},
volume={},
number={},
pages={127-134},
abstract={This paper presents an end-user oriented approach of describing mobile devices as RESTful services. The mobile services are provided to the end-users through a centralized server. To enable plugging of devices, they provide a machine-processable device description with detailed specification of their RESTful API. The device description is used to generate required user interface as well as generating the RESTful invocations. We provide general guidelines on how to design a REST API for a mobile device and a device description for machine-to-machine interactions. The approach is demonstrated by building a centralized marketplace to promote and use available mobile services. The central marketplace acts as a broker for the dynamic mobile services. In addition, we use two case study applications to demonstrate the service registration, provisioning, and usage.},
keywords={application program interfaces;human computer interaction;mobile computing;Web services;mobile devices;RESTful services;end-user oriented approach;mobile services;centralized server;machine-processable device description;RESTful API;user interface;RESTful invocations;machine-to-machine interactions;centralized marketplace;service registration;service provisioning;service usage;Mobile Service;Internet of Things;Machine-to-Machine;End-Users},
doi={10.1109/MobServ.2016.27},
ISSN={2329-6453},
month={June},}
@INPROCEEDINGS{7510921,
author={P. A. {Frangoudis} and L. {Yala} and A. {Ksentini} and T. {Taleb}},
booktitle={2016 IEEE International Conference on Communications (ICC)},
title={An architecture for on-demand service deployment over a telco CDN},
year={2016},
volume={},
number={},
pages={1-6},
abstract={Internet Service Providers are becoming more involved in the audiovisual content delivery chain. One manifestation of this trend is the emergence of telco CDNs, i.e., content delivery networks operated by telecom service providers. In this work, we make the case for opening the telco CDN infrastructure to content providers by means of network function virtualization (NFV) and cloud technologies. We design and implement a CDN-as-a-Service architecture, where content providers can lease CDN resources on demand at regions where the ISP has presence. Using open northbound RESTful APIs, content providers can express performance requirements and demand specifications, which can be translated to an appropriate service placement on the underlying cloud substrate. To gain insight which can be applied to the design of such service placement mechanisms, we evaluate the capabilities of key enabling virtualization technologies by extensive testbed experiments.},
keywords={application program interfaces;audio-visual systems;cloud computing;computer network performance evaluation;service-oriented architecture;virtualisation;on-demand service deployment architecture;Internet service providers;audiovisual content delivery chain;content delivery networks;telecom service providers;telco CDN infrastructure;network function virtualization;NFV;cloud technologies;CDN-as-a-service architecture;content providers;CDN resources;ISP;open northbound RESTful API;performance requirements;demand specifications;service placement mechanisms;Cloud computing;Servers;Virtualization;Computer architecture;Resource management},
doi={10.1109/ICC.2016.7510921},
ISSN={1938-1883},
month={May},}
@INPROCEEDINGS{7389129,
author={N. {Pazos} and M. {MÃ¼ller} and M. {Aeberli} and N. {Ouerhani}},
booktitle={2015 IEEE 2nd World Forum on Internet of Things (WF-IoT)},
title={ConnectOpen - automatic integration of IoT devices},
year={2015},
volume={},
number={},
pages={640-644},
abstract={There exists, today, a wide consensus that Internet of Things (IoT) is creating a wide range of business opportunities for various industries and sectors like Manufacturing, Healthcare, Public infrastructure management, Telecommunications and many others. On the other hand, the technological evolution of IoT facing serious challenges. The fragmentation in terms of communication protocols and data formats at device level is one of these challenges. Vendor specific application architectures, proprietary communication protocols and lack of IoT standards are some reasons behind the IoT fragmentation. In this paper we propose a software enabled framework to address the fragmentation challenge. The framework is based on flexible communication agents that are deployed on a gateway and can be adapted to various devices communicating different data formats using different communication protocol. The communication agent is automatically generated based on specifications and automatically deployed on the Gateway in order to connect the devices to a central platform where data are consolidated and exposed via REST APIs to third party services. Security and scalability aspects are also addressed in this work.},
keywords={application program interfaces;cloud computing;computer network security;Internet of Things;internetworking;transport protocols;scalability aspect;security aspect;third party services;REST API;central platform;communication protocol;communication agents;software enabled framework;IoT fragmentation;device level;data formats;communication protocols;Internet of Things;automatic IoT device integration;ConnectOpen;Logic gates;Sensors;Protocols;Business;Security;Scalability;Embedded systems;IoT;Gateway;End Device;OSGi;Kura;Communication Agent;MQTT},
doi={10.1109/WF-IoT.2015.7389129},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8360326,
author={S. {Challita} and F. {Zalila} and C. {Gourdin} and P. {Merle}},
booktitle={2018 IEEE International Conference on Cloud Engineering (IC2E)},
title={A Precise Model for Google Cloud Platform},
year={2018},
volume={},
number={},
pages={177-183},
abstract={Today, Google Cloud Platform (GCP) is one of the leaders among cloud APIs. Although it was established only five years ago, GCP has gained notable expansion due to its suite of public cloud services that it based on a huge, solid infrastructure. GCP allows developers to use these services by accessing GCP RESTful API that is described through HTML pages on its website. However, the documentation of GCP API is written in natural language (English prose) and therefore shows several drawbacks, such as Informal Heterogeneous Documentation, Imprecise Types, Implicit Attribute Metadata, Hidden Links, Redundancy and Lack of Visual Support. To avoid confusion and misunderstandings, the cloud developers obviously need a precise specification of the knowledge and activities in GCP. Therefore, this paper introduces GCP Model, an inferred formal model-driven specification of GCP which describes without ambiguity the resources offered by GCP. GCP Model is conform to the Open Cloud Computing Interface (OCCI) metamodel and is implemented based on the open source model-driven Eclipse-based OCCIware tool chain. Thanks to our GCP Model, we offer corrections to the drawbacks we identified.},
keywords={application program interfaces;cloud computing;Google Cloud Platform;cloud APIs;public cloud services;GCP RESTful API;GCP API;Open Cloud Computing Interface metamodel;Documentation;Cloud computing;Computational modeling;Semantics;Google;Visualization;Natural languages;Cloud computing;Google cloud platform;OCCI;Model driven engineering},
doi={10.1109/IC2E.2018.00041},
ISSN={},
month={April},}
@INPROCEEDINGS{7987452,
author={J. {WÃ¥hslÃ©n} and T. {Lindh}},
booktitle={2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM)},
title={Real-time performance management of assisted living services for Bluetooth low energy sensor communication},
year={2017},
volume={},
number={},
pages={1143-1148},
abstract={PerfMon is a prototype implementation of a real-time performance management method for sensor data communication in assisted living applications. It is implemented in accordance with the specification for GATT services in Bluetooth low energy (BLE). PerfMon provides a tool for real-time performance monitoring and control for caregivers and service providers. Test results from monitoring and control of packet loss ratio related to alarm thresholds are presented. PerfMon is adapted to cloud-based web services using RESTful APIs and established object models. Performance management is a necessary component in an overall management system of IoT devices for healthcare and assisted living applications.},
keywords={assisted living;Bluetooth;data communication;health care;Internet of Things;medical computing;real-time performance management;assisted living services;Bluetooth low energy sensor communication;PerfMon;cloud-based Web services;RESTful API;sensor data communication;GATT services;BLE;IoT devices;healthcare;Trade agreements;Monitoring;Protocols;Bluetooth;Servers;Performance evaluation;Logic gates;performance monitoring;performance management;Internet of Things;Bluetooth low energy;Generic Attribute (GATT) service;ambient assisted living},
doi={10.23919/INM.2017.7987452},
ISSN={},
month={May},}
